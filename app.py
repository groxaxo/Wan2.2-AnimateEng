# app.py
import os
import oss2
import sys
import uuid
import shutil
import time
import gradio as gr
import requests

import dashscope
from dashscope.utils.oss_utils import check_and_upload_local

DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
dashscope.api_key = DASHSCOPE_API_KEY


class WanAnimateApp:
    def __init__(self, url, get_url):
        self.url = url
        self.get_url = get_url

    def predict(
        self, 
        ref_img,
        video,
        model_id,
        model,
    ):
        # Upload files to OSS if needed and get URLs
        _, image_url = check_and_upload_local(model_id, ref_img, DASHSCOPE_API_KEY)
        _, video_url = check_and_upload_local(model_id, video, DASHSCOPE_API_KEY)

        # Prepare the request payload
        payload = {
            "model": model_id,
            "input": {
                "image_url": image_url,
                "video_url": video_url
            },
            "parameters": {
                "check_image": True,
                "mode": model,
            }
        }
        
        # Set up headers
        headers = {
            "X-DashScope-Async": "enable",
            "X-DashScope-OssResourceResolve": "enable",
            "Authorization": f"Bearer {DASHSCOPE_API_KEY}",
            "Content-Type": "application/json"
        }
        
        # Make the initial API request
        url = self.url
        response = requests.post(url, json=payload, headers=headers)
        
        # Check if request was successful
        if response.status_code != 200:
            raise Exception(f"Initial request failed with status code {response.status_code}: {response.text}")
        
        # Get the task ID from response
        result = response.json()
        task_id = result.get("output", {}).get("task_id")
        if not task_id:
            raise Exception("Failed to get task ID from response")
        
        # Poll for results
        get_url = f"{self.get_url}/{task_id}"
        headers = {
            "Authorization": f"Bearer {DASHSCOPE_API_KEY}",
            "Content-Type": "application/json"
        }
        
        while True:
            response = requests.get(get_url, headers=headers)
            if response.status_code != 200:
                raise Exception(f"Failed to get task status: {response.status_code}: {response.text}")
            
            result = response.json()
            print(result)
            task_status = result.get("output", {}).get("task_status")
            
            if task_status == "SUCCEEDED":
                # Task completed successfully, return video URL
                video_url = result["output"]["results"]["video_url"]
                return video_url, "SUCCEEDED"
            elif task_status == "FAILED":
                # Task failed, raise an exception with error message
                error_msg = result.get("output", {}).get("message", "Unknown error")
                code_msg = result.get("output", {}).get("code", "Unknown code")
                print(f"\n\nTask failed: {error_msg} Code: {code_msg} TaskId: {task_id}\n\n")
                return None, f"Task failed: {error_msg} Code: {code_msg} TaskId: {task_id}"
                # raise Exception(f"Task failed: {error_msg} TaskId: {task_id}")
            else:
                # Task is still running, wait and retry
                time.sleep(5)  # Wait 5 seconds before polling again

def start_app():
    import argparse
    parser = argparse.ArgumentParser(description="Wan2.2-Animate è§†é¢‘ç”Ÿæˆå·¥å…·")
    args = parser.parse_args()
    
    url = "https://dashscope.aliyuncs.com/api/v1/services/aigc/image2video/video-synthesis/"
    # url = "https://poc-dashscope.aliyuncs.com/api/v1/services/aigc/image2video/video-synthesis"

    get_url = f"https://dashscope.aliyuncs.com/api/v1/tasks/"
    # get_url = f"https://poc-dashscope.aliyuncs.com/api/v1/tasks"
    app = WanAnimateApp(url=url, get_url=get_url)

    with gr.Blocks(title="Wan2.2-Animate è§†é¢‘ç”Ÿæˆ") as demo:
        gr.HTML("""

            
            <div style="padding: 2rem; text-align: center; max-width: 1200px; margin: 0 auto; font-family: Arial, sans-serif;">

                <h1 style="font-size: 2.5rem; font-weight: bold; margin-bottom: 0.5rem; color: #333;">
                    Wan2.2-Animate: Unified Character Animation and Replacement with Holistic Replication
                </h1>
                
                <h3 style="font-size: 2.5rem; font-weight: bold; margin-bottom: 0.5rem; color: #333;">
                    Wan2.2-Animate: ç»Ÿä¸€çš„è§’è‰²åŠ¨ç”»å’Œè§†é¢‘äººç‰©æ›¿æ¢æ¨¡å‹
                </h3>

                <div style="font-size: 1.25rem; margin-bottom: 1.5rem; color: #555;">
                    Tongyi Lab, Alibaba
                </div>

                <div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 1rem; margin-bottom: 1rem;">
                    <!-- ç¬¬ä¸€è¡ŒæŒ‰é’® -->
                    <a href="https://arxiv.org/abs/2509.14055" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; /* æµ…ç°è‰²èƒŒæ™¯ */ color: #333; /* æ·±è‰²æ–‡å­— */ text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ“„</span> <!-- ä½¿ç”¨æ–‡æ¡£å›¾æ ‡ -->
                        <span>Paper</span>
                    </a>

                    <a href="https://github.com/Wan-Video/Wan2.2" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; color: #333; text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ’»</span> <!-- ä½¿ç”¨ç”µè„‘å›¾æ ‡ -->
                        <span>GitHub</span>
                    </a>

                    <a href="https://huggingface.co/Wan-AI/Wan2.2-Animate-14B" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; color: #333; text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ¤—</span>
                        <span>HF Model</span>
                    </a>

                    <a href="https://www.modelscope.cn/models/Wan-AI/Wan2.2-Animate-14B" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; color: #333; text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ¤–</span>
                        <span>MS Model</span>
                    </a>
                </div>

                <div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 1rem;">
                    <!-- ç¬¬äºŒè¡ŒæŒ‰é’® -->
                    <a href="https://huggingface.co/spaces/Wan-AI/Wan2.2-Animate" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; color: #333; text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ¤—</span>
                        <span>HF Space</span>
                    </a>

                    <a href="https://www.modelscope.cn/studios/Wan-AI/Wan2.2-Animate" target="_blank"
                    style="display: inline-flex; align-items: center; padding: 0.5rem 1rem; background-color: #f0f0f0; color: #333; text-decoration: none; border-radius: 9999px; font-weight: 500; transition: background-color 0.3s;">
                        <span style="margin-right: 0.5rem;">ğŸ¤–</span>
                        <span>MS Studio</span>
                    </a>
                </div>

            </div>
            
            """)
        
        gr.HTML("""
                <details>
                    <summary>â€¼ï¸Usage (ä½¿ç”¨è¯´æ˜)</summary>
                    
                    Wan-Animate supports two mode:
                    <ul>
                        <li>Move Mode: animate the  character in input image with movements from the input video</li>
                        <li>Mix Mode: replace the character in input video with the character in input image</li>
                    </ul>
                    
                    Wan-Animate æ”¯æŒä¸¤ç§æ¨¡å¼:
                    <ul>
                        <li>Moveæ¨¡å¼: ç”¨è¾“å…¥è§†é¢‘ä¸­æå–çš„åŠ¨ä½œï¼Œé©±åŠ¨è¾“å…¥å›¾ç‰‡ä¸­çš„è§’è‰²</li>
                        <li>Mixæ¨¡å¼: ç”¨è¾“å…¥å›¾ç‰‡ä¸­çš„è§’è‰²ï¼Œæ›¿æ¢è¾“å…¥è§†é¢‘ä¸­çš„è§’è‰²</li>
                    </ul>

                    Currently, the following restrictions apply to inputs:

                    <ul> <li>Video file size: Less than 200MB</li> 
                    <li>Video resolution: The shorter side must be greater than 200, and the longer side must be less than 2048</li> 
                    <li>Video duration: 2s to 30s</li> 
                    <li>Video aspect ratio: 1:3 to 3:1</li> 
                    <li>Video formats: mp4, avi, mov</li> 
                    <li>Image file size: Less than 5MB</li> 
                    <li>Image resolution: The shorter side must be greater than 200, and the longer side must be less than 4096</li> 
                    <li>Image formats: jpg, png, jpeg, webp, bmp</li> </ul>

                    
                    å½“å‰ï¼Œå¯¹äºè¾“å…¥æœ‰ä»¥ä¸‹çš„é™åˆ¶ 

                    <ul>
                        <li>è§†é¢‘æ–‡ä»¶å¤§å°: å°äº 200MB</li>
                        <li>è§†é¢‘åˆ†è¾¨ç‡ï¼š æœ€å°è¾¹å¤§äº 200, æœ€å¤§è¾¹å°äº2048</li>
                        <li>è§†é¢‘æ—¶é•¿: 2s ~ 30s </li> 
                        <li>è§†é¢‘æ¯”ä¾‹ï¼š1:3 ~ 3:1 </li>
                        <li>è§†é¢‘æ ¼å¼: mp4, avi, mov </li> 
                        <li>å›¾ç‰‡æ–‡ä»¶å¤§å°: å°äº5MB </li>
                        <li>å›¾ç‰‡åˆ†è¾¨ç‡ï¼šæœ€å°è¾¹å¤§äº200ï¼Œæœ€å¤§è¾¹å°äº4096 </li>
                        <li>å›¾ç‰‡æ ¼å¼: jpg, png, jpeg, webp, bmp </li> 
                    </ul>     
                    
                    <p> Currently, the inference quality has two variants. You can use our open-source code for more flexible configuration. </p>
                    
                    <p>å½“å‰ï¼Œæ¨ç†è´¨é‡æœ‰ä¸¤ä¸ªå˜ç§ã€‚ æ‚¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„å¼€æºä»£ç ï¼Œæ¥è¿›è¡Œæ›´çµæ´»çš„è®¾ç½®ã€‚</p>
                    
                    <ul>
                        <li> wan-pro: 25fps, 720p </li> 
                        <li> wan-std: 15fps, 720p  </li>
                    </ul>     
                              

                </details>                
                """)

        with gr.Row():
            with gr.Column():    
                ref_img = gr.Image(
                    label="Reference Image(å‚è€ƒå›¾åƒ)",
                    type="filepath",
                    sources=["upload"],
                )
                
                video = gr.Video(
                    label="Template Video(æ¨¡ç‰ˆè§†é¢‘)",
                    sources=["upload"],
                )
                
                with gr.Row():
                    model_id = gr.Dropdown(
                        label="Mode(æ¨¡å¼)",
                        choices=["wan2.2-animate-move", "wan2.2-animate-mix"],
                        value="wan2.2-animate-move",
                        info=""
                    )

                    model = gr.Dropdown(
                        label="æ¨ç†è´¨é‡(Inference Quality)",
                        choices=["wan-pro", "wan-std"],
                        value="wan-pro",
                    )

                run_button = gr.Button("Generate Video(ç”Ÿæˆè§†é¢‘)")

            with gr.Column():
                output_video = gr.Video(label="Output Video(è¾“å‡ºè§†é¢‘)")
                output_status = gr.Textbox(label="Status(çŠ¶æ€)")
        
        run_button.click(
            fn=app.predict,
            inputs=[
                ref_img,
                video,
                model_id,
                model,
            ],
            outputs=[output_video, output_status],
        )

        example_data = [
            ['./examples/mov/1/1.jpeg', './examples/mov/1/1.mp4', 'wan2.2-animate-move', 'wan-pro'],
            ['./examples/mov/2/2.jpeg', './examples/mov/2/2.mp4', 'wan2.2-animate-move', 'wan-pro'],
            ['./examples/mix/1/1.jpeg', './examples/mix/1/1.mp4', 'wan2.2-animate-mix', 'wan-pro'],
            ['./examples/mix/2/2.jpeg', './examples/mix/2/2.mp4', 'wan2.2-animate-mix', 'wan-pro']
        ]

        if example_data:
            gr.Examples(
                examples=example_data,
                inputs=[ref_img, video, model_id, model],
                outputs=[output_video, output_status],
                fn=app.predict,
                cache_examples="lazy",
            )
    
    demo.queue(default_concurrency_limit=100)
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860
    )


if __name__ == "__main__":
    start_app()